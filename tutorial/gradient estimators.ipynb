{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVI and gradient estimators\n",
    "\n",
    "### Setup\n",
    "\n",
    "We've defined a Pyro model with observations ${\\bf x}$ and latents ${\\bf z}$ of the form $p_{\\theta}({\\bf x}, {\\bf z}) = p_{\\theta}({\\bf x}|{\\bf z}) p_{\\theta}({\\bf z})$. We've also defined a Pyro guide (i.e. a variational distribution) of the form $q_{\\rm \\phi}({\\bf z})$. Here ${\\theta}$ and $\\phi$ are variational parameters for the model and guide, respectively. (In particular these are _not_ random variables that call for a Bayesian treatment).\n",
    "\n",
    "We'd like to maximize the log evidence $\\log p_{\\theta}({\\bf x})$ by maximizing the ELBO (the evidence lower bound) given by \n",
    "\n",
    "${\\rm ELBO} \\equiv \\mathbb{E}_{q_{\\phi}({\\bf z})} \\left [ \n",
    "\\log p_{\\theta}({\\bf x}, {\\bf z}) - \\log q_{\\phi}({\\bf z})\n",
    "\\right]$\n",
    "\n",
    "To do this we're going to take (stochastic) gradient steps on the ELBO in the parameter space $\\{ \\theta, \\phi \\}$ (see reference [1] for early work on this approach). So we need to be able to compute unbiased estimates of \n",
    "\n",
    "$\\nabla_{\\theta,\\phi} {\\rm ELBO} = \\nabla_{\\theta,\\phi}\\mathbb{E}_{q_{\\phi}({\\bf z})} \\left [ \n",
    "\\log p_{\\theta}({\\bf x}, {\\bf z}) - \\log q_{\\phi}({\\bf z})\n",
    "\\right]$\n",
    "\n",
    "How do we do this for general stochastic functions `model()` and `guide()`? To simplify notation let's generalize our discussion a bit and ask how we can compute gradients of expectations of an arbitrary cost function $f({\\bf z})$. Let's also drop any distinction between $\\theta$ and $\\phi$. So we want to compute\n",
    "\n",
    "$\\nabla_{\\phi}\\mathbb{E}_{q_{\\phi}({\\bf z})} \\left [\n",
    "f_{\\phi}({\\bf z}) \\right]$\n",
    "\n",
    "Let's start with the easiest case.\n",
    "\n",
    "### The easiest case: reparameterizable random variables\n",
    "\n",
    "Suppose that we can reparameterize things such that \n",
    "\n",
    "$\\mathbb{E}_{q_{\\phi}({\\bf z})} \\left [f_{\\phi}({\\bf z}) \\right]\n",
    "=\\mathbb{E}_{q({\\bf \\epsilon})} \\left [f_{\\phi}(g_{\\phi}({\\bf \\epsilon})) \\right]$\n",
    "\n",
    "Crucially we've moved all the $\\phi$ dependence inside of the exectation; $q({\\bf \\epsilon})$ is a fixed distribution with no dependence on $\\phi$. This kind of reparameterization can be done for many distributions (e.g. the normal distribution); see reference [2] for a discussion. In this case we can pass the gradient straight through the expectation to get\n",
    "\n",
    "$\\nabla_{\\phi}\\mathbb{E}_{q({\\bf \\epsilon})} \\left [f_{\\phi}(g_{\\phi}({\\bf \\epsilon})) \\right]=\n",
    "\\mathbb{E}_{q({\\bf \\epsilon})} \\left [\\nabla_{\\phi}f_{\\phi}(g_{\\phi}({\\bf \\epsilon})) \\right]$\n",
    "\n",
    "Assuming $f(\\cdot)$ and $g(\\cdot)$ are sufficiently smooth, we can now get unbiased estimates of the gradient of interest by taking a Monte Carlo estimate of this expectation.\n",
    "\n",
    "### The trickier case: non-reparameterizable random variables\n",
    "\n",
    "What if we can't do the above reparameterization? Unfortunately this is the case for many distributions of interest, for example all discrete distributions. In this case our estimator takes a bit more complicated form.\n",
    "\n",
    "We begin by expanding the gradient of interest as\n",
    "\n",
    "$\\nabla_{\\phi}\\mathbb{E}_{q_{\\phi}({\\bf z})} \\left [\n",
    "f_{\\phi}({\\bf z}) \\right]= \n",
    "\\nabla_{\\phi} \\int d{\\bf z} \\; q_{\\phi}({\\bf z}) f_{\\phi}({\\bf z})$\n",
    "\n",
    "and use the chain rule to write this as \n",
    "\n",
    "$ \\int d{\\bf z} \\; \\left \\{ (\\nabla_{\\phi}  q_{\\phi}({\\bf z})) f_{\\phi}({\\bf z}) + q_{\\phi}({\\bf z})(\\nabla_{\\phi} f_{\\phi}({\\bf z}))\\right \\} $\n",
    "\n",
    "At this point we run into a problem. We know how to take samples from $q(\\cdot)$ (we just run the guide forward) but $\\nabla_{\\phi}  q_{\\phi}({\\bf z})$ isn't even a valid probability density. So we need to massage this formula so that it's in the form of an expectation w.r.t. $q(\\cdot)$. This is easily done using the identity\n",
    "\n",
    "$ \\nabla_{\\phi}  q_{\\phi}({\\bf z}) = \n",
    "q_{\\phi}({\\bf z})\\nabla_{\\phi} \\log q_{\\phi}({\\bf z})$\n",
    "\n",
    "which allows us to rewrite the gradient of interest as \n",
    "\n",
    "$\\mathbb{E}_{q_{\\phi}({\\bf z})} \\left [\n",
    "(\\nabla_{\\phi} \\log q_{\\phi}({\\bf z})) f_{\\phi}({\\bf z}) + \\nabla_{\\phi} f_{\\phi}({\\bf z})\\right]$\n",
    "\n",
    "This form of the gradient estimator&mdash;variously known as the REINFORCE estimator or score function estimator or the likelihood ratio estimator&mdash;is amenable to simple Monte Carlo estimation.\n",
    "\n",
    "Note that one way to package this result (which is covenient for implementation) is to introduce a surrogate loss function\n",
    "\n",
    "${\\rm surrogate \\;loss} \\equiv\n",
    "\\log q_{\\phi}({\\bf z}) \\overline{f_{\\phi}({\\bf z})} + f_{\\phi}({\\bf z})$\n",
    "\n",
    "Here the bar indicates that the term is held constant (i.e. it is not to be differenated w.r.t. $\\phi$). To get a (single-sample) Monte Carlo gradient estimate, we sample the latent random variables, compute the surrogate loss, and differentiate. The result is an unbiased estimate of $\\nabla_{\\phi}\\mathbb{E}_{q_{\\phi}({\\bf z})} \\left [\n",
    "f_{\\phi}({\\bf z}) \\right]$.\n",
    "\n",
    "### Variance or Why I Wish I Was Doing MLE Deep Learning\n",
    "\n",
    "We now have a general recipe for an unbiased gradient estimator of expectations of cost functions. Unfortunately, in the more general case where our $q(\\cdot)$ includes non-reparameterizable random variables, this estimator tends to have high variance. Indeed in many cases of interest the variance is so high that the estimator is effectively unusable. So we need strategies to reduce variance (for a discussion see reference [3]). We're going to pursue two strategies. The first strategy takes advantage of the particular structure of the cost function $f(\\cdot)$. The second strategy effectively introduces a way to reduce variance by using information from previous estimates of \n",
    "$\\mathbb{E}_{q_{\\phi}({\\bf z})} [ f_{\\phi}({\\bf z})]$. As such it is somewhat analogous to using momentum in stochastic gradient descent. \n",
    "\n",
    "### Reducing variance by paying attention to dependency structure\n",
    "\n",
    "In the above discussion we stuck to a general cost function $f_{\\phi}({\\bf z})$. We could continue in this vein (the approach we're about to discuss is applicable in the general case) but for concreteness let's zoom back in. In the case of stochastic variational inference, we're interested in a particular cost function of the form\n",
    "\n",
    "$\\log p_{\\theta}({\\bf x} | {\\rm Pa}_p ({\\bf x})) +\n",
    "\\sum_i p_{\\theta}({\\bf z}_i | {\\rm Pa}_p ({\\bf z}_i)) \n",
    "- \\sum_i \\log q_{\\phi}({\\bf z}_i | {\\rm Pa}_q ({\\bf z}_i))$\n",
    "\n",
    "where we've broken the log ratio $\\log p_{\\theta}({\\bf x}, {\\bf z})/q_{\\phi}({\\bf z})$ into a sum over the different latent random variables $\\{{\\bf z}_i \\}$. We've also introduced the notation \n",
    "${\\rm Pa}_p (\\cdot)$ and ${\\rm Pa}_q (\\cdot)$ to denote the parents of a particle random variable in the model and in the guide, respectively. (The reader might worry what the appropriate notion of dependency would be in the case of general stochastic functions; here we simply mean regular ol' dependency within a single execution trace). The point is that different terms in the cost function have different dependencies on the random variables $\\{ {\\bf z}_i \\}$ and this is something we can take advantage of.\n",
    "\n",
    "To make a long story short, for any non-reparameterizable latent random variable ${\\bf z}_i$ the surrogate loss is going to have a term \n",
    "\n",
    "$\\log q_{\\phi}({\\bf z}_i) \\overline{f_{\\phi}({\\bf z})} $\n",
    "\n",
    "It turns out that we can remove some of the terms in $\\overline{f_{\\phi}({\\bf z})}$ and still get an unbiased gradient estimator; furthermore, doing so will generally decrease the variance. In particular (see reference [3] for details) we can remove any terms in $\\overline{f_{\\phi}({\\bf z})}$ that are not downstream of the latent variable ${\\bf z}_i$ (downstream w.r.t. to the dependency structure of the guide). \n",
    "\n",
    "In Pyro, all of this logic is taken care of automatically by the `SVI` class. In particular as long as we switch on `trace_graph=True`, Pyro will keep track of the dependency structure within the execution traces of the model and guide and construct a surrogate loss that has all the unnecessary terms removed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "elbo = SVI(model, guide, optimizer, \"ELBO\", trace_graph=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that leveraging this dependency information takes extra computations, so `trace_graph=True` should only be invoked in the case where your model has non-reparameterizable random variables. \n",
    "\n",
    "\n",
    "### Aside: Dependency tracking in Pyro\n",
    "\n",
    "Finally, a word about dependency tracking. Tracking dependency within a stochastic function that includes arbitrary Python code is a bit tricky. The approach currently implemented in Pyro is analogous to the one used in WebPPL (cf. reference [4]). Briefly, a conservative notion of dependency is used that relies on sequential ordering. If random variable ${\\bf z}_2$ follows ${\\bf z}_1$ in a given stochastic function then ${\\bf z}_2$ _may be_ dependent on ${\\bf z}_1$ and therefore _is_ assumed to be dependent. To mitigate the overly coarse conclusions drawn by this kind of dependency, Pyro includes constructs for declaring things as independent, namely `irange` and `iarange` [**SEE LINK**]. For use cases with non-reparameterizable variables, it is therefore important for the user to make use of these constructs to take full advantage of the variance reduction provided by `SVI`. In some cases it may also pay to consider reordering random variables within a stochastic function (if possible). It's also worth noting that we expect to add finer notions of dependency tracking in a future version of Pyro.\n",
    "\n",
    "### Reducing variance with data-dependent baselines\n",
    "\n",
    "The second strategy for reducing variance in our ELBO gradient estimator goes under the name of baselines (see e.g. reference [5]). It actually makes use of the same bit of math that underlies the variance reduction strategy discussed above, except now instead of removing terms we're going to add terms. Basically, instead of removing terms with zero expectation that tend to _contribute_ to the variance, we're going to add specially chosen terms with zero expectation that work to _reduce_ the variance.\n",
    "\n",
    "blah blah blah"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1] `Black Box Variational Inference`,<br/>&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "Rajesh Ranganath, Sean Gerrish, David M. Blei\n",
    "\n",
    "[2] `Auto-Encoding Variational Bayes`,<br/>&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "Diederik P Kingma, Max Welling\n",
    "\n",
    "[3] `Gradient Estimation Using Stochastic Computation Graphs`,\n",
    "<br/>&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "    John Schulman, Nicolas Heess, Theophane Weber, Pieter Abbeel\n",
    "    \n",
    "[4] `Deep Amortized Inference for Probabilistic Programs`\n",
    "<br/>&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "Daniel Ritchie, Paul Horsfall, Noah D. Goodman\n",
    "\n",
    "[5] `Neural Variational Inference and Learning in Belief Networks`\n",
    "<br/>&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "Andriy Mnih, Karol Gregor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
